{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi_epidata import Epidata\n",
    "# Fetch data\n",
    "# how to import the library and fetch national FluView data for epiweeks 201440 and 201501-201510 (11 weeks total).\n",
    "\n",
    "\n",
    "res = Epidata.fluview(['nat'], [201440, Epidata.range(201501, 201510)])\n",
    "print(res['result'], res['message'], len(res['epidata']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = Epidata.fluview(['hhs1'], [201440, Epidata.range(201501, 201510)])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crawl_data_to_feature_specific(startepiweek, endepiweek, regions):\n",
    "    '''\n",
    "    This function crawls data from the delphi epidata API and stores it in a csv file.\n",
    "\n",
    "    :param startepiweek: the first epiweek to crawl\n",
    "    :param endepiweek: the last epiweek to crawl\n",
    "    :param regions: the list of regions to crawl\n",
    "\n",
    "    return: a dataframe of the data\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    from delphi_epidata import Epidata\n",
    "    region_dic={\n",
    "        'nat':0,\n",
    "        'hhs1':1,\n",
    "        'hhs2':2,\n",
    "        'hhs3':3,\n",
    "        'hhs4':4,\n",
    "        'hhs5':5,\n",
    "        'hhs6':6,\n",
    "        'hhs7':7,\n",
    "        'hhs8':8,\n",
    "        'hhs9':9,\n",
    "        'hhs10':10,\n",
    "\n",
    "    }\n",
    "\n",
    "    filename = regions[0]+'_'+str(startepiweek)+'_'+str(endepiweek)+'.feather'\n",
    "    res = Epidata.fluview(regions, [Epidata.range(startepiweek, endepiweek)])\n",
    "    epidata = res['epidata']\n",
    "    df = pd.DataFrame(columns=['Season', 'Epidemic_week', 'HHS_region', 'wILI'])\n",
    "    for i in epidata:   \n",
    "        # print(i)\n",
    "        epiWeek = str(i['epiweek'])\n",
    "        Year = epiWeek[0:4]\n",
    "        Week = epiWeek[4:6]\n",
    "        if int(Week) <= 20:\n",
    "            preYear = int(Year) - 1\n",
    "            Season = str(preYear) + \"/\" + str(Year)\n",
    "        elif int(Week) >= 40:\n",
    "            Season = str(Year) + \"/\" + str(int(Year) + 1)\n",
    "        else:\n",
    "            continue\n",
    "        df = df.append({'Season': Season, 'Epidemic_week': epiWeek, 'HHS_region': region_dic[i['region']], 'wILI': i['wili']}, ignore_index=True)\n",
    "    df = df.sort_values(by=['Epidemic_week','HHS_region']).reset_index(drop=True)\n",
    "    # store the data as feather\n",
    "    df.to_feather(filename)\n",
    "    return df\n",
    "\n",
    "def crawl_data_to_feature_all(startepiweek, endepiweek):\n",
    "    '''\n",
    "    This function crawls data from the delphi epidata API and stores it in a feather file.\n",
    "\n",
    "    :param startepiweek: the first epiweek to crawl\n",
    "    :param endepiweek: the last epiweek to crawl   \n",
    "    :return: a dataframe of all the data\n",
    "\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    from delphi_epidata import Epidata\n",
    "    regions = ['nat','hhs1','hhs2','hhs3','hhs4','hhs5','hhs6','hhs7','hhs8','hhs9','hhs10']\n",
    "    df = pd.DataFrame(columns=['Season', 'Epidemic_week', 'HHS_region', 'wILI'])\n",
    "    for i in regions:\n",
    "        df1 = crawl_data_to_feature_specific(startepiweek, endepiweek, [i])\n",
    "        df = pd.concat([df, df1], ignore_index=True)\n",
    "    df = df.sort_values(by=['Epidemic_week','HHS_region']).reset_index(drop=True)\n",
    "    # store the data as feather\n",
    "    df.to_feather('all_' + str(startepiweek) + '_' + str(endepiweek) + '.feather')\n",
    "    return df\n",
    "\n",
    "# crawl_data_to_csv(200901, 202218)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = crawl_data_to_csv_all(200901, 202218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Epidemic_week</th>\n",
       "      <th>HHS_region</th>\n",
       "      <th>wILI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>200901</td>\n",
       "      <td>0</td>\n",
       "      <td>1.471378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>200901</td>\n",
       "      <td>1</td>\n",
       "      <td>0.628376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>200901</td>\n",
       "      <td>2</td>\n",
       "      <td>1.657290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>200901</td>\n",
       "      <td>3</td>\n",
       "      <td>1.664776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008/2009</td>\n",
       "      <td>200901</td>\n",
       "      <td>4</td>\n",
       "      <td>1.181011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>2021/2022</td>\n",
       "      <td>202218</td>\n",
       "      <td>6</td>\n",
       "      <td>2.209420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>2021/2022</td>\n",
       "      <td>202218</td>\n",
       "      <td>7</td>\n",
       "      <td>1.428680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>2021/2022</td>\n",
       "      <td>202218</td>\n",
       "      <td>8</td>\n",
       "      <td>2.890620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>2021/2022</td>\n",
       "      <td>202218</td>\n",
       "      <td>9</td>\n",
       "      <td>1.934710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>2021/2022</td>\n",
       "      <td>202218</td>\n",
       "      <td>10</td>\n",
       "      <td>2.019860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4939 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Season Epidemic_week HHS_region      wILI\n",
       "0     2008/2009        200901          0  1.471378\n",
       "1     2008/2009        200901          1  0.628376\n",
       "2     2008/2009        200901          2  1.657290\n",
       "3     2008/2009        200901          3  1.664776\n",
       "4     2008/2009        200901          4  1.181011\n",
       "...         ...           ...        ...       ...\n",
       "4934  2021/2022        202218          6  2.209420\n",
       "4935  2021/2022        202218          7  1.428680\n",
       "4936  2021/2022        202218          8  2.890620\n",
       "4937  2021/2022        202218          9  1.934710\n",
       "4938  2021/2022        202218         10  2.019860\n",
       "\n",
       "[4939 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['2010/2011', '2011/2012'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probobilility_dic should sum to 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0942ec17907e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprobobilility_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"2010/2011\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2011/2012\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobobilility_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrandomly_select_fluseason\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobobilility_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nat_200901_202218.feather'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-0942ec17907e>\u001b[0m in \u001b[0;36mrandomly_select_fluseason\u001b[0;34m(probobilility_dic, season_features_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobobilility_dic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'probobilility_dic should sum to 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probobilility_dic should sum to 1"
     ]
    }
   ],
   "source": [
    "def randomly_select_fluseason(probobilility_dic,season_features_path):\n",
    "    '''\n",
    "    randomly select a flu season based on the probability_dic\n",
    "\n",
    "    :param probobilility_dic: a dictionary of flu season and its probability(sum of all probabilility should be 1)\n",
    "    :param season_features_path: the path of the season features csv file\n",
    "    \n",
    "    :return: a dataframe of the flu season features\n",
    "    '''\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    features = pd.read_feather(season_features_path)\n",
    "\n",
    "    if sum(probobilility_dic.values()) != 1:\n",
    "        raise ValueError('probobilility_dic should sum to 1')\n",
    "    else:       \n",
    "        keys = np.array(list(probobilility_dic.keys()))\n",
    "        values = np.array(list(probobilility_dic.values()))\n",
    "        season = np.random.choice(keys, 1,p=values)[0]\n",
    "        features = features[features['Season'] == season]\n",
    "        return features\n",
    "\n",
    "    \n",
    "probobilility_list = {\"2010/2011\":0.1,\"2011/2012\":0.1}\n",
    "print(probobilility_list.keys())\n",
    "randomly_select_fluseason(probobilility_list,'nat_200901_202218.feather')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143 0.2857142857142857\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHSRegion</th>\n",
       "      <th>EpidemicWeek</th>\n",
       "      <th>Season</th>\n",
       "      <th>wILI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>4.213740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2014/2015</td>\n",
       "      <td>4.210220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017/2018</td>\n",
       "      <td>6.517590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>2.251120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2016/2017</td>\n",
       "      <td>4.436010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>0.807851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>2017/2018</td>\n",
       "      <td>1.657700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>2017/2018</td>\n",
       "      <td>1.822670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2015/2016</td>\n",
       "      <td>1.383020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2016/2017</td>\n",
       "      <td>1.418610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HHSRegion EpidemicWeek     Season      wILI\n",
       "0          0            1  2014/2015  4.213740\n",
       "1          0            2  2014/2015  4.210220\n",
       "2          0            3  2017/2018  6.517590\n",
       "3          0            4  2015/2016  2.251120\n",
       "4          0            5  2016/2017  4.436010\n",
       "..       ...          ...        ...       ...\n",
       "61         1           48  2015/2016  0.807851\n",
       "62         1           49  2017/2018  1.657700\n",
       "63         1           50  2017/2018  1.822670\n",
       "64         1           51  2015/2016  1.383020\n",
       "65         1           52  2016/2017  1.418610\n",
       "\n",
       "[66 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_generate_fluseason(startyear,endyear,features,regions=None):\n",
    "    '''\n",
    "    randomly generate a flu season\n",
    "\n",
    "    :param startyear: the start year of the flu season\n",
    "    :param endyear: the end year of the flu season\n",
    "    :param features: the features of the flu season\n",
    "    :param regions: the list of regions to generate the flu season[0,1]\n",
    "    '''\n",
    "    # choose the region from features\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    if regions is None:\n",
    "        regions = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "    features = features[features['HHS_region'].isin(regions)]  \n",
    "    year33 = [2009,2010,2011,2012,2013,2015,2016,2017,2018,2019,2021,2022,2023,2024]\n",
    "    year34 = [2014,2020]\n",
    "    year33_count = []\n",
    "    year34_count = []\n",
    "    for i in range(startyear,endyear+1):\n",
    "        if i in year33:\n",
    "            year33_count.append(i)\n",
    "        elif i in year34:\n",
    "            year34_count.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    year33_prob = len(year33_count)/(len(year33_count)+len(year34_count))\n",
    "    year34_prob = len(year34_count)/(len(year33_count)+len(year34_count))\n",
    "    print(year33_prob,year34_prob)\n",
    "    random_year = np.random.choice([33,34],1,p=[year33_prob,year34_prob])[0]\n",
    "    def get_season(is33year,yearlist,df):\n",
    "        teamdf = pd.DataFrame(columns=['HHSRegion','EpidemicWeek','Season','wILI'])\n",
    "        if is33year:\n",
    "            epiweeks = np.array(list(range(1,21))+list(range(40,54)))\n",
    "        else:\n",
    "            epiweeks = np.array(list(range(1,21))+list(range(40,55)))\n",
    "        for r in regions:\n",
    "            df1 = df[df['HHS_region'] == r]\n",
    "            for epiweek in epiweeks:\n",
    "                yearweek = []\n",
    "                for i in yearlist:\n",
    "                    if epiweek < 10:\n",
    "                        yearweek.append(str(i)+'0'+str(epiweek))\n",
    "                    else:\n",
    "                        yearweek.append(str(i)+str(epiweek))\n",
    "                df2 = df1[df1['Epidemic_week'].isin(yearweek)]\n",
    "                # randomly select a row from the dataframe\n",
    "                if len(df2) == 0:\n",
    "                    continue\n",
    "                df2 = df2.reset_index(drop=True)\n",
    "                \n",
    "                row_index = random.randint(0,len(df2)-1)\n",
    "                row = df2.iloc[row_index]\n",
    "                teamdf = teamdf.append({'HHSRegion':r,'EpidemicWeek':epiweek,'Season':row['Season'],'wILI':row['wILI']},ignore_index=True)\n",
    "        return teamdf\n",
    "\n",
    "\n",
    "\n",
    "    if random_year == 33:\n",
    "        df = get_season(True,year33_count,features)\n",
    "    elif random_year == 34:\n",
    "        df = get_season(False,year34_count,features)\n",
    "    return df\n",
    "    \n",
    "import pandas as pd\n",
    "features = pd.read_feather('all_200901_202218.feather')\n",
    "df = random_generate_fluseason(2014,2020,features,[0,1])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Week(2020, 1, CDC)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def modelweek(E):\n",
    "   from epiweeks import Week\n",
    "   cdc_start = Week(1946,27)\n",
    "   modelweek = E - cdc_start\n",
    "   return modelweek\n",
    "\n",
    "from epiweeks import Week\n",
    "# modelweek(Week(2020,1))\n",
    "Week(2020,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('random_season.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.array(list(range(1,21))+list(range(40,54)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a3d88c904243d2c3f246166597f86d1c0a39f3d97496d1fe394945d0c6d436d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
